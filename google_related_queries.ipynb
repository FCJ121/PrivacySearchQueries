{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from collections import OrderedDict\n",
    "from random import shuffle\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import argparse\n",
    "import csv\n",
    "import urllib\n",
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"A method that cleans the list of obtained queries by removing stopwords\n",
    "from every query and return the cleaned queries as a list\"\"\"\n",
    "def clean_obtained_queries(queries, stop):\n",
    "    clean_queries = []\n",
    "    for q in queries:\n",
    "        words = word_tokenize(q)\n",
    "        query = (\" \".join([i for i in words if i not in stop])).strip(' .,\\'')\n",
    "        clean_queries.append(query)\n",
    "    return clean_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"A method that calculates overlap between a list of related \n",
    "queries and the global set of already approved queries.\"\"\"\n",
    "def get_overlap(approved_queries, approved_ngrams, related_queries, method):\n",
    "    if method == 'n' and len(approved_ngrams) == 0:\n",
    "        return 1    \n",
    "    if method == 's' or len(approved_queries) == 0:\n",
    "        return 1    \n",
    "    if len(related_queries) == 0:\n",
    "        return 0\n",
    "    count = 0.0\n",
    "    print approved_ngrams\n",
    "    print related_queries\n",
    "    for item in related_queries:\n",
    "        if method == 'n':\n",
    "            item_set = set(item.split())\n",
    "            if len(item_set) in approved_ngrams:\n",
    "                len_list = approved_ngrams[len(item_set)]\n",
    "                if len_list is not None:\n",
    "                    for ngram in len_list:\n",
    "                        inter = item_set & set(ngram.split())\n",
    "                        if len(inter) == len(item_set):\n",
    "                            count += 1\n",
    "                            break\n",
    "        elif method == 's':\n",
    "            if item in approved_queries.keys():\n",
    "                count += 1\n",
    "            \n",
    "    control_size = min(len(approved_queries), len(related_queries))\n",
    "    return count/control_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_related_queries(seed, threshold, factor, method, approved, rejected):\n",
    "    name_suffix = './googledata/' + seed.replace(' ', '_') + '_' + str(threshold) + '_' + str(factor) + '_' + method + '_'\n",
    "    a_name =  name_suffix + 'approved.csv'\n",
    "    r_name = name_suffix + 'rejected.csv'\n",
    "        \n",
    "    with open(a_name, 'w') as f:\n",
    "        csv_writer = csv.writer(f, lineterminator='\\n')\n",
    "        for (k, v) in approved.iteritems():\n",
    "            csv_writer.writerow([k, v])\n",
    "            \n",
    "    with open(r_name, 'w') as f:\n",
    "        csv_writer = csv.writer(f, lineterminator='\\n')\n",
    "        for (k, v) in rejected.iteritems():\n",
    "            csv_writer.writerow([k, v])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def google_related_searches(query):\n",
    "    try:\n",
    "        address = \"http://www.google.com/search?q=%s&num=100&hl=en&start=0\" % (urllib.quote_plus(query))\n",
    "        request = urllib2.Request(address, None, {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11'})\n",
    "        urlfile = urllib2.urlopen(request)\n",
    "        page = urlfile.read()\n",
    "    except Exception as e:\n",
    "        print 'Error retrieving google search results: ' + str(e)\n",
    "        return False, list()\n",
    "    \n",
    "    # Strip the related search portion using beautifulsoup.\n",
    "    rs = list()\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    rsdiv = soup.find(\"div\", { \"id\" : \"brs\" })\n",
    "    for d in rsdiv.findAll('div', {'class':'brs_col'}):\n",
    "        for p in d.findAll('p', {'class':'_e4b'}):\n",
    "            rs.append(p.getText())\n",
    "    return True, rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Structure to hold search queries by the length of their ngram. This is\n",
    "    # find a faster lookup for determining overlap values quickly.\n",
    "    approved_ngrams = dict()\n",
    "\n",
    "    #A dictionary of approved queries along with their overlap value\n",
    "    approved_queries = OrderedDict() \n",
    "    rejected_queries = OrderedDict()\n",
    "\n",
    "    # A set maintained for related queries where the overlap value was zero.\n",
    "    # This can happen when either none of the related keywords appear in the\n",
    "    # approved ngrams or we could not find any related keywords for the\n",
    "    # given seed query.\n",
    "    junk_related_keywords = set()\n",
    "    \n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    ap = argparse.ArgumentParser(description='Find related searches using the google search scraping.')\n",
    "    ap.add_argument('-s', '-seed', help='Seed word', required=True)\n",
    "    ap.add_argument('-t', '-threshold', help='Overlapping threshold', default=0.25)\n",
    "    ap.add_argument('-f', '-factor', help='Selection factor of approved related keywords', default=1.00)\n",
    "    ap.add_argument('-o', '-overlap', help='Overlapping measurement method (n)gram or (s)tring', default='n')\n",
    "    args = ap.parse_args()\n",
    "    \n",
    "    # Default values\n",
    "    seed_word = args.s\n",
    "    threshold = float(args.t)\n",
    "    selection_factor = float(args.f)\n",
    "    overlap_method = args.o\n",
    "    \n",
    "    try:\n",
    "        newset = [seed_word]\n",
    "        while 0 < len(newset) and len(newset) < 40000:\n",
    "            new_query = newset.pop(0)\n",
    "\n",
    "            # If this query appears anywhere in the approved, rejected, or\n",
    "            # junk queries, then don't process it.\n",
    "            if  (new_query in approved_queries) or (new_query in rejected_queries) or (new_query in junk_related_keywords):\n",
    "                continue\n",
    "\n",
    "            # Fetch the related searches.\n",
    "            success, related_keywords = google_related_searches(new_query)            \n",
    "            \n",
    "            # Check if we failed to retrieve the related searches.\n",
    "            if not success:\n",
    "                # Put back the query in the candidate set and try again.\n",
    "                newset.insert(0, new_query)\n",
    "                continue\n",
    "\n",
    "            # Remove stopwords from the related keywords.\n",
    "            related_keywords = clean_obtained_queries(related_keywords, stop)\n",
    "\n",
    "            # Get overlap value\n",
    "            overlap_value = get_overlap(approved_queries, approved_ngrams, related_keywords, overlap_method)\n",
    "\n",
    "            if overlap_value >= threshold:\n",
    "                # Overlap value is beyond threshold. Save the new \n",
    "                # query's overlap value and add it to the approved\n",
    "                # queries list.\n",
    "                approved_queries[new_query] = overlap_value\n",
    "\n",
    "                # The related keywords are now cadidates for further\n",
    "                # related keyword fetching.\n",
    "                subset_index = int(selection_factor * len(related_keywords))\n",
    "                shuffle(related_keywords)\n",
    "                newset.extend(related_keywords[0:subset_index])\n",
    "\n",
    "                # Add the new query to the approved ngrams.\n",
    "                l = len(new_query.split())\n",
    "                approved_ngrams.setdefault(l, list()).append(new_query)\n",
    "            else:\n",
    "                # Reject the new query.\n",
    "                rejected_queries[new_query] = overlap_value\n",
    "\n",
    "                # If the overlap value is zero, then add them to junk queries.\n",
    "                if overlap_value == 0:\n",
    "                    junk_related_keywords |= set(related_keywords)\n",
    "    except Exception as e:\n",
    "        print 'Error processing related search ' + str(e)\n",
    "    finally:\n",
    "        save_related_queries(seed_word, threshold, selection_factor, overlap_method, approved_queries, rejected_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
